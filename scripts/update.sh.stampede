#!/bin/bash

# May 2013
# Kyle Marcus

# This script should be called by cron to update the stampede tacc_stats files that are mirrored on this server
# Stampede.tacc.utexas.edu tacc_stats files located at /scratch/projects/tacc_stats
# tas-db1 mirrors these files on /data/scratch/Stampede
# This script has also been updated to include creating the pickle files for the current day

# Update archive tacc_stats raw data files for each node
# NOTE: if a new node is added on Stampede, then it will need to be added here first in order for it to update,
#       each individual node is updated with rsync because it seems to run faster this way instead of doing the
#       rsync for the whole archive/ directory. The rsync command used here will exclude any files that are 
#       older than 2 days, this makes the updating process much faster! It will spawn 25 process at once and 
#       will continue to create new process (with a max of 25 at a time) until all the nodes have been updated.

CONTROLPATH="$HOME/.ssh/ctl/$$-%L-%r@%h:%p"
RSYNCRSH="ssh -i /user/xdtas/.ssh/id_dsa_xdtas_xsede_cron -o ControlPath=${CONTROLPATH}"

# Create initial ssh connection
ssh -i /user/xdtas/.ssh/id_dsa_xdtas_xsede_cron -MnNf -o ControlMaster=yes -o ControlPersist=yes -o ControlPath=${CONTROLPATH} xdtas@login2.stampede.tacc.utexas.edu

# Update accounting file
date
rsync -v -t -z -e "${RSYNCRSH}" xdtas@login2.stampede.tacc.utexas.edu:/scratch/projects/tacc_stats/accounting/tacc_jobs_completed /data/scratch/Stampede/accounting/tacc_jobs_completed

# Update hostfiles
date
rsync -v -t -r -e "${RSYNCRSH}" xdtas@login2.stampede.tacc.utexas.edu:/scratch/projects/tacc/hostfile_logs /data/scratch/Stampede

# Update lariat data
date
rsync -v -t -r -e "${RSYNCRSH}" xdtas@login2.stampede.tacc.utexas.edu:/scratch/projects/lariatData /data/scratch/Stampede

###
ssh -i /user/xdtas/.ssh/id_dsa_xdtas_xsede_cron -o ControlPath=${CONTROLPATH} xdtas@login2.stampede.tacc.utexas.edu "./rawTaccStatsTarTransfer.sh" | tar xfk - -C /data/scratch/Stampede/archive
###

#date
#cd /data/scratch/Stampede/archive
#for f in /data/scratch/Stampede/archive/*
#do
#	if [ -d $f ]
#	then
#		x=`basename $f`
#		find $x -type f -mtime +2 | sed 's_.*/__' | rsync --exclude-from - -t -r -v -e 'ssh -i /user/xdtas/.ssh/id_dsa_xdtas_xsede_cron -o "ControlPath='$HOME'/.ssh/ctl/%L-%r@%h:%p"' xdtas@login2.stampede.tacc.utexas.edu:/scratch/projects/tacc_stats/archive/$x /data/scratch/Stampede/archive &
#	fi
#	while [ `jobs -p | wc -l` -gt 15 ]
#	do
#		sleep 1
#	done
#done

#wait

# create the pickle for today, pickles are stored in /data/scratch/Stampede/pickles
#date
#/data/scratch/tacc_stats_kylemarcus/monitor/do_job_pickles_cron.sh /data/scratch/Stampede/pickle.conf

# get pickle from stampede
d=$(date -d 'now -2 days' +%F)
rsync -v -t -e "${RSYNCRSH}" xdtas@login2.stampede.tacc.utexas.edu:/scratch/projects/tacc_stats/pickles/${d}.tar.gz /data/scratch/Stampede/pickles/${d}.tar.gz

# close the ssh session
ssh -O exit -o ControlPath=${CONTROLPATH} xdtas@login2.stampede.tacc.utexas.edu

# create summaries, for each date create a .tar.gz file that is put into ifs
mkdir -p /dev/shm/logs/batchSummary/Stampede/
mkdir -p /dev/shm/tmp/Stampede/
/user/xdtas/kmarcus2/batchSummary.sh ${d} Stampede > /dev/shm/logs/batchSummary/Stampede/${d}.o 2> /dev/shm/logs/batchSummary/Stampede/${d}.e

# put sumaries into mongo
#python /user/xdtas/kmarcus2/summaryConvertToMongo.py /ifs/projects/xdtas/summaries/stampede/${d}-json stampede >/dev/shm/logs/mongo/Stampede/${d}.o 2>/dev/shm/logs/mongo/Stampede/${d}.e
mkdir -p /dev/shm/logs/mongo/Stampede/
python /user/xdtas/kmarcus2/summaryConvertToMongo.py /dev/shm/json/Stampede/${d}-json stampede >/dev/shm/logs/mongo/Stampede/${d}.o 2>/dev/shm/logs/mongo/Stampede/${d}.e
rm -r /dev/shm/json/Stampede/${d}-json

